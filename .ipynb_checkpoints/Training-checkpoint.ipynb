{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5ad5d66-65d4-4abf-a29e-0a919ab0964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import ipynb\n",
    "\n",
    "from ipynb.fs.full.LSTM_char import *\n",
    "from ipynb.fs.full.Data_import_preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a570e935-44ee-40ab-b150-bc2d0714f521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "def tr_device_fn(GPU = False):\n",
    "    '''info of GPU support\n",
    "    Input\n",
    "    GPU: bool - GPU support\n",
    "    Output\n",
    "    device: obj\n",
    "    '''\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() and torch.backends.mps.is_built() and GPU else \"cpu\")\n",
    "    return device\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = tr_device_fn(GPU = True)\n",
    "    print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d3fbd1-666d-457d-b549-367e77d2ea93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Characters: \n",
      "144059\n",
      "Total Vocab: \n",
      "47\n",
      "Total Patterns: \n",
      "143959\n",
      "\n",
      "\n",
      "\n",
      "Size of X: torch.Size([143959, 100, 1]) Size of y: torch.Size([143959]) \n",
      "\n",
      "\n",
      "start: 2023-11-20 08:28:57.692182 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def tr_training(X, y, model, optimizer, loss_fn, char_to_int, n_epochs, batch_size, device, save = False, verbose = False):\n",
    "    '''Train the model\n",
    "    Input\n",
    "    X: tensor - training data shape of (batch size/sequence length/1)\n",
    "    y: tensor - response vector\n",
    "    model: obj - nn model\n",
    "    optimizer: nn optimizer\n",
    "    loss_fn: nn loss funciton\n",
    "    char_to_int: dict - character to integer mapping\n",
    "    n_epochs: number of epoch\n",
    "    batch_size: batch size\n",
    "    device: device cpu or mps\n",
    "    save: save model\n",
    "    verbose: print\n",
    "    Output\n",
    "    model: obj\n",
    "    '''\n",
    "\n",
    "    start = datetime.now()\n",
    "    if verbose:\n",
    "        print('\\nstart:', start, '\\n')\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    loader = data.DataLoader(data.TensorDataset(X, y), shuffle=True, batch_size=batch_size)\n",
    "    best_model = None\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in loader:\n",
    "            y_pred = model(X_batch.to(device))\n",
    "            loss = loss_fn(y_pred, y_batch.to(device))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in loader:\n",
    "                y_pred = model(X_batch.to(device))\n",
    "                loss += loss_fn(y_pred, y_batch.to(device))\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_model = model.state_dict()\n",
    "            if verbose:\n",
    "                print(\"Epoch %d: Cross-entropy: %.4f\" % (epoch+1, loss))\n",
    "\n",
    "        # Estimated end\n",
    "        end = datetime.now() \n",
    "        diff = end - start\n",
    "        if verbose:\n",
    "            print('estimated end:', start + diff * (n_epochs - epoch))\n",
    "        start = end\n",
    "\n",
    "    if verbose:\n",
    "        print('\\nend:', datetime.now(), '\\n', '\\n')\n",
    "\n",
    "    if save:\n",
    "        m = str(model)\n",
    "        m = m[0: m.find('(')]\n",
    "        id = str(int(datetime.now().timestamp()))\n",
    "        torch.save([best_model, char_to_int], (m + '_' + id + '.pth') )\n",
    "        print('\\nModel(weights + char_to_int) saved as: ' + (m + '_' + id + '.pth') + ' in directory: ' + os.getcwd(), '\\n')\n",
    "\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    seq_length = 100\n",
    "    n_epochs = 1\n",
    "    batch_size = 128\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "    text = dip_load_data('/Users/danielboda', 'wonderland.txt')\n",
    "    chars, char_to_int, int_to_char = dip_chars_dict(text)\n",
    "    X, y, n_patterns, n_vocab = dip_create_data(text, chars, char_to_int, verbose = True)   \n",
    "    X, y = dip_normalization_reshape(X, y, n_patterns, n_vocab, 100, verbose = True) \n",
    "    model = lc_CharModel(n_vocab)\n",
    "    device = tr_device_fn(GPU = True)\n",
    "    model = tr_training(X, y, model, optimizer, loss_fn, char_to_int, n_epochs, n_epochs, device, save = True, verbose = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
