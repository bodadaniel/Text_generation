{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7247675f-9ffc-4e72-82ae-fe5c9f2ed819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import ipynb\n",
    "\n",
    "from ipynb.fs.full.LSTM_char import *\n",
    "from ipynb.fs.full.Data_import_preprocessing import *\n",
    "from ipynb.fs.full.Training import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14e8f8e3-a2bc-4e61-93f4-4eb982e37ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = dip_load_data('/Users/danielboda', 'wonderland.txt')\n",
    "chars, char_to_int, int_to_char = dip_chars_dict(text)\n",
    "\n",
    "model = lc_CharModel(47)\n",
    "\n",
    "X = torch.randint(1, 100, (128, 100, 1), dtype=torch.float32)\n",
    "X = X / float(47)\n",
    "\n",
    "y = torch.randint(1, 47, (128,), dtype=torch.float32).type(torch.LongTensor)\n",
    "#print(X.size(), y.size(), model(X).size())\n",
    "\n",
    "n_epochs = 2\n",
    "batch_size = 128\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "device = tr_device_fn(GPU = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d597a288-f2a4-453b-9a76-329617af6143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s ready to ask help of any one; so, when the\n",
      "rabbit came near her, she began, in a low, timid voice,\n"
     ]
    }
   ],
   "source": [
    "def ev_text_gen_prompt(text, char_to_int, seq_len, verbose = False):\n",
    "    '''generate random prompt text\n",
    "    Input\n",
    "    text: string - raw text\n",
    "    char_to_int: dict - character to integer mapping\n",
    "    seq_len: int - sequence length (example: XXXY/First three training/fourth label => seq_length = 3) \n",
    "    verbose: bool - print \n",
    "    Output\n",
    "    prompt: str, prompt: list - numeric form \n",
    "    '''\n",
    "\n",
    "    random_start = np.random.randint(0, len(text) - seq_len)\n",
    "    prompt = text[random_start : random_start + seq_len]\n",
    "    prompt_int = [char_to_int[c] for c in prompt]\n",
    "    \n",
    "    if verbose:\n",
    "        print('\\n', prompt, '\\n')\n",
    "\n",
    "    return prompt, prompt_int\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    prompt, prompt_int = ev_text_gen_prompt(text, char_to_int, 100, verbose = True)\n",
    "    #print(pattern)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb0b2a36-fbe5-4be3-b329-965c0a2f8e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \"s ready to ask help of any one; so, when the\n",
      "rabbit came near her, she began, in a low, timid voice,\"\n",
      "Generated: \n",
      "zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz"
     ]
    }
   ],
   "source": [
    "def ev_eval(X, prompt, n_text, n_vocab, model, device, load_model = None, verbose = False):\n",
    "    '''evaluation by writing out the generated text starting from prompt\n",
    "    Input\n",
    "    X: list - numeric form of prompt\n",
    "    prompt: string - text input\n",
    "    n_text: int - number of generated character\n",
    "    n_vocab: int - size of vocab\n",
    "    model: obj - nn model\n",
    "    device: obj - device\n",
    "    load_model: none\n",
    "    verbose: bool - print \n",
    "    Output\n",
    "    result: list - generated text \n",
    "    '''\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    if verbose:\n",
    "        print('\\nPrompt: \"%s\"' % prompt)\n",
    "    result_all = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(n_text):\n",
    "            x = np.reshape(X, (1, len(X), 1)) / float(n_vocab)\n",
    "            x = torch.tensor(x, dtype=torch.float32).to(device)\n",
    "            prediction = model(x)\n",
    "            index = int(prediction.argmax())\n",
    "            result = int_to_char[index]\n",
    "            result_all.append(result)\n",
    "            X.append(index)\n",
    "            X[1:]\n",
    "\n",
    "            if verbose:\n",
    "                if i == 0:\n",
    "                    print('Generated: ')\n",
    "                print(result, end = \"\")\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "    return result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ev_eval(prompt_int, prompt, 100, 47, model, device, load_model = None, verbose = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a25112-b8c2-4ae0-a752-0b4b0c684884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684702ce-5c7b-49f2-9f0b-ab8db555d21c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
